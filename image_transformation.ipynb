{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f61b0310-5d69-4dd1-a0d4-4812d2ef18a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5eac0ddf-b572-44c7-98fc-cf2d98bf9430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input image\n",
    "image = cv2.imread(\"buga.png\")\n",
    "cv2.imshow(\"original image\", image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# reducing the original image by half\n",
    "half_scaled = cv2.resize(image, dsize = None, fx = 0.5, fy = 0.5)\n",
    "cv2.imshow(\"half scaled image\", half_scaled)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# increasing image scaled with interpolation\n",
    "increse_scale = cv2.resize(image, dsize = None, fx = 1.5, fy= 1.5, interpolation = cv2.INTER_AREA)\n",
    "cv2.imshow(\"Increased scale\", increse_scale)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# skewing an image by including 'dsize' parameter\n",
    "scew = cv2.resize(image, dsize = (760, 150), interpolation = cv2.INTER_AREA)\n",
    "cv2.imshow(\"scew\", scew)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c692c840-3bfc-45c6-9c6f-914cb054ff89",
   "metadata": {},
   "source": [
    "### Scaling by image pyramid\n",
    " Image pyramids comes handy. The pyrUp() function increases the size to double of its original size and pyrDown() function decreases the size to half.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "967ab112-916b-475c-9914-48c34fd6fe60",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"buga.png\")\n",
    "cv2.imshow(\"original image\", image)\n",
    "cv2.waitKey(0)\n",
    "# scaling up\n",
    "large = cv2.pyrUp(image)\n",
    "cv2.imshow(\"large pyramid\", large)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# scaling down\n",
    "small = cv2.pyrDown(image)\n",
    "cv2.imshow(\"scaaling down pyramid\", small)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb64962-eb1e-4342-a845-955adf463be0",
   "metadata": {},
   "source": [
    "### Rotation and Flip using OpenCV\n",
    "cv2.getRotationMatrix2D(rotation_center_x, rotation_center_y, angle of rotation, scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7767b91-0180-4990-b6e5-536a88d340cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5044c5c7-095d-46bc-b3ee-29130d9c88d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((373, 557, 3), (373, 557))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# geting the shape of the input image \n",
    "image = cv2.imread(\"buga.png\")\n",
    "\n",
    "# image.shape prints out the shape of an image \n",
    "# image.shape[:2] output the first 2 columns\n",
    "image.shape, image.shape[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9fa9d5d6-aad3-49d6-8d39-727c72065f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the input image \n",
    "image = cv2.imread(\"buga.png\")\n",
    "cv2.imshow(\"original image\", image)\n",
    "\n",
    "# getting the height and width of the image \n",
    "height, width = image.shape[:2]\n",
    "\n",
    "# dividing height and width by 2 to rotate the image about it center. we use the rotation matrx\n",
    "rotation_mat = cv2.getRotationMatrix2D( (height/2, width/2), 45, 1)\n",
    "\n",
    "rotate_image_output = cv2.warpAffine(image, rotation_mat, (width, height))\n",
    "cv2.imshow(\"rotated image\", rotate_image_output)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c164b5d-329b-44f5-8a96-470297cf1dc4",
   "metadata": {},
   "source": [
    "### Flipping an image horizontally or vertically \n",
    "cv2.flip(image, flip_code(1 or 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1bde4409-45f4-4571-afae-01df002fcba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"buga.png\")\n",
    "cv2.imshow(\"original image\", image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# flipping vertically \n",
    "v_flip = cv2.flip(image, 0)\n",
    "cv2.imshow(\"vertical flip\", v_flip)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# horizontal flip\n",
    "h_flip = cv2.flip(image, 1)\n",
    "cv2.imshow(\"horizontal flip\", h_flip)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7504a1-2804-402c-a6f7-1bd41b968421",
   "metadata": {},
   "source": [
    "### Image Translation \n",
    "this is moving image from one location to another\n",
    "in image translation, translation matrix is used \n",
    "\n",
    "#### Translation Matrix elements\n",
    "#####           | 1 0 Tx |\n",
    "#####    | 0 1 Ty  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa49ef29-0275-4053-95be-32b305f7949e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "373 557\n",
      "==========\n",
      "[[  1.     0.    93.25]\n",
      " [  0.     1.   139.25]]\n"
     ]
    }
   ],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "\n",
    "# load input image \n",
    "image =  cv2.imread(\"buga.png\")\n",
    "cv2.imshow(\"original image\", image)\n",
    "\n",
    "# extracting height and width of the image \n",
    "height, width = image.shape[:2]\n",
    "print(height, width)\n",
    "print(\"==========\")\n",
    "\n",
    "# translate the height and width of the image to 1/4\n",
    "height_forth, width_forth = height/4, width/4\n",
    "\n",
    "# applying translation matrix\n",
    "T = np.float32([[1, 0, height_forth], [0, 1, width_forth]])\n",
    "\n",
    "# let us view the translation matrix\n",
    "print(T)\n",
    "\n",
    "# using wrapAffine to transform the image using the translation matrix, T\n",
    "translation = cv2.warpAffine(image, T, (width, height))\n",
    "cv2.imshow(\"Translated image\", translation)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1c74225b-e8f1-4b03-a008-8c07677f4ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "for x in range(0,4):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d7259c-9e90-43fc-9140-6077478451e2",
   "metadata": {},
   "source": [
    " ### Adjusting image brightness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1f302d3d-913d-4c73-810e-e93e08398c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[90 90 90]\n",
      "  [90 90 90]\n",
      "  [90 90 90]\n",
      "  ...\n",
      "  [90 90 90]\n",
      "  [90 90 90]\n",
      "  [90 90 90]]\n",
      "\n",
      " [[90 90 90]\n",
      "  [90 90 90]\n",
      "  [90 90 90]\n",
      "  ...\n",
      "  [90 90 90]\n",
      "  [90 90 90]\n",
      "  [90 90 90]]\n",
      "\n",
      " [[90 90 90]\n",
      "  [90 90 90]\n",
      "  [90 90 90]\n",
      "  ...\n",
      "  [90 90 90]\n",
      "  [90 90 90]\n",
      "  [90 90 90]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[90 90 90]\n",
      "  [90 90 90]\n",
      "  [90 90 90]\n",
      "  ...\n",
      "  [90 90 90]\n",
      "  [90 90 90]\n",
      "  [90 90 90]]\n",
      "\n",
      " [[90 90 90]\n",
      "  [90 90 90]\n",
      "  [90 90 90]\n",
      "  ...\n",
      "  [90 90 90]\n",
      "  [90 90 90]\n",
      "  [90 90 90]]\n",
      "\n",
      " [[90 90 90]\n",
      "  [90 90 90]\n",
      "  [90 90 90]\n",
      "  ...\n",
      "  [90 90 90]\n",
      "  [90 90 90]\n",
      "  [90 90 90]]]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# load original image\n",
    "img = cv2.imread(\"bettle.webp\")\n",
    "cv2.imshow(\"original image\", img)\n",
    "\n",
    "# creating a matrix of ones using the image dimensions as our matrix dimension\n",
    "intensity_mat = np.ones(img.shape, dtype = \"uint8\") * 90\n",
    "\n",
    "# print  the intensity matrix\n",
    "print(intensity_mat)\n",
    "\n",
    "# add intensity matrix to the input image in order to increase the brightness\n",
    "bright_img = cv2.add(img, intensity_mat)\n",
    "cv2.imshow(\"bright image\", bright_img)\n",
    "\n",
    "# subtract to darken the image \n",
    "dark = cv2.subtract(img, intensity_mat)\n",
    "cv2.imshow(\"darken image\", dark)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea084f6-3e8b-4d1c-83d7-6137b3edd86c",
   "metadata": {},
   "source": [
    "### how to crop an image using indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8102d10e-e33d-41c5-8cf9-eb767d7ec136",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3aa3b8dc-8943-4ad2-98f5-e6394463c9e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "height of image 1024\n",
      "width of image 1024\n",
      "cropped image shape:  (615, 615, 3)\n"
     ]
    }
   ],
   "source": [
    "# importing the image \n",
    "img = cv2.imread(\"bettle.webp\")\n",
    "\n",
    "# extracting the height and width of the image\n",
    "height, width = img.shape[:2]\n",
    "print(\"height of image\", height)\n",
    "print(\"width of image\", width)\n",
    "\n",
    "# extract the pixel starting point you want to crop (starting from the left)\\\n",
    "start_row, start_col = int(height * 0.2), int(width * 0.2)\n",
    "\n",
    "# extracting the row and column you want to end the cropping \n",
    "end_row, end_col = int(height * 0.8), int(width * 0.8)\n",
    "\n",
    "# using the indexing method to crop the image \n",
    "cropped_img = img[start_row: end_row, start_col:end_col]\n",
    "# printing the shape of the cropped image \n",
    "print(\"cropped image shape: \", cropped_img.shape)\n",
    "\n",
    "# displaying both original and cropped\n",
    "cv2.imshow(\"original image\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.imshow(\"cropped image\", cropped_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f89051-9586-4b2c-9db5-843887fd5115",
   "metadata": {},
   "source": [
    "### image masking \n",
    "This involves hiding some portion of the image editing where it hides some portions of an image. \n",
    "this is doen basically by adding shapes to the image and using bit wise operators (logic condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "619c7801-7367-42f6-9e17-62d59661eb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40393640-f8ae-4293-b28a-311454a10d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw a greyscale (number of channel = 1) square\n",
    "square_image = np.zeros((400, 400, 1), np.uint8)\n",
    "cv2.rectangle(square_image, (70, 70), (300, 300), 255, -2)\n",
    "cv2.imshow(\"Square\", square_image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Draw greyscale (number of channel = 1)\n",
    "circle = np.zeros((400, 400, 1), np.uint8)\n",
    "cv2.circle(circle, (300, 300), 70, (255,0,0), -1)\n",
    "cv2.imshow(\"Circle\", circle)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39991531-b730-4902-b7c5-6d168bbcd71b",
   "metadata": {},
   "source": [
    "#### using bit wise operations on the shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35a8f717-7eed-4da9-a5d3-cc41e5398c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# showing the region where both square and circle intersect\n",
    "AND_operations = cv2.bitwise_and(square_image, circle)\n",
    "cv2.imshow(\"AND operation\", AND_operations)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# showing the region where either the square or circle is\n",
    "OR_operation = cv2.bitwise_or(square_image, circle)\n",
    "cv2.imshow(\"OR operation\", OR_operation)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# showing the region where either circle or square exists (XOR)\n",
    "XOR_operation = cv2.bitwise_xor(square_image, circle)\n",
    "cv2.imshow(\"XOR operation\", XOR_operation )\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# showing the region that is not part of square i.e inverse of the square image\n",
    "NOT_operation = cv2.bitwise_not(square_image)\n",
    "cv2.imshow(\"NOT operation\", NOT_operation)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f8125d-5a33-4010-8c7c-53e27a2248d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Bluring an image\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
